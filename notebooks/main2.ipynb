{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def calculate_area(wkt_polygon):\\n    polygon = wkt.loads(wkt_polygon)\\n    return polygon.area\\n     \\n      \\n    This function is deprecated'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def calculate_area(wkt_polygon):\n",
    "    polygon = wkt.loads(wkt_polygon)\n",
    "    return polygon.area\n",
    "     \n",
    "      \n",
    "    This function is deprecated\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '1232cd7984e543e188eebab0f8d6956f'\n",
    "\n",
    "def get_coordinates(county, name):\n",
    "    place_name = f\"{name}, {county} County, Florida\"\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={place_name}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data['results']:\n",
    "        location = data['results'][0]['geometry']\n",
    "        return (location['lat'], location['lng'])\n",
    "    else:\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is gonna get our coordenates using the OpenCage Geocoding API using a key provided by one of the data scientists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates(county, name, state=\"Florida\"):\n",
    "    place_name = f\"{name}, {county} County, {state}\"\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={place_name}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data['results']:\n",
    "        location = data['results'][0]['geometry']\n",
    "        return (location['lat'], location['lng'])\n",
    "    else:\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(lat1, lon1, lat2, lon2):\n",
    "    # This function calculates the manhattan distance between two places\n",
    "    return abs(lat2 - lat1) + abs(lon2 - lon1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WKT</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>NAME</th>\n",
       "      <th>created_user</th>\n",
       "      <th>created_date</th>\n",
       "      <th>last_edited_user</th>\n",
       "      <th>last_edited_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON Z ((-9698711.156 3546590.3287 0,-96987...</td>\n",
       "      <td>ESCAMBIA</td>\n",
       "      <td>UNSURVEYED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON Z ((-9061671.5384 3555608.0978 0,-9061...</td>\n",
       "      <td>DUVAL</td>\n",
       "      <td>HANNA PARK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON Z ((-9054509.0537 3514807.6314 0,-9054...</td>\n",
       "      <td>ST JOHNS</td>\n",
       "      <td>GUANA RIVER SP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON Z ((-9668169.2045 3552697.6667 0,-9668...</td>\n",
       "      <td>ESCAMBIA</td>\n",
       "      <td>UNSURVEYED</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON Z ((-9597884.3653 3547578.4878 0,-9597...</td>\n",
       "      <td>WALTON</td>\n",
       "      <td>WALTON COUNTY BCHS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>POLYGON Z ((-9039717.3304 2937286.6217 0,-9039...</td>\n",
       "      <td>MONROE</td>\n",
       "      <td>ENP (HIGHLAND BEAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>POLYGON Z ((-9039593.2653 2937286.6434 0,-9039...</td>\n",
       "      <td>MONROE</td>\n",
       "      <td>ENP (HIGHLAND BEAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>POLYGON Z ((-9015596.0256 2844170.7527 0,-9015...</td>\n",
       "      <td>MONROE</td>\n",
       "      <td>LITTLE CRAWL KEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>POLYGON Z ((-9016208.8296 2843020.5594 0,-9016...</td>\n",
       "      <td>MONROE</td>\n",
       "      <td>FAT DEER KEY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>POLYGON Z ((-8927112.0082 2930542.2383 0,-8927...</td>\n",
       "      <td>DADE</td>\n",
       "      <td>BISCAYNE NATIONAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>302 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   WKT    COUNTY  \\\n",
       "0    POLYGON Z ((-9698711.156 3546590.3287 0,-96987...  ESCAMBIA   \n",
       "1    POLYGON Z ((-9061671.5384 3555608.0978 0,-9061...     DUVAL   \n",
       "2    POLYGON Z ((-9054509.0537 3514807.6314 0,-9054...  ST JOHNS   \n",
       "3    POLYGON Z ((-9668169.2045 3552697.6667 0,-9668...  ESCAMBIA   \n",
       "4    POLYGON Z ((-9597884.3653 3547578.4878 0,-9597...    WALTON   \n",
       "..                                                 ...       ...   \n",
       "297  POLYGON Z ((-9039717.3304 2937286.6217 0,-9039...    MONROE   \n",
       "298  POLYGON Z ((-9039593.2653 2937286.6434 0,-9039...    MONROE   \n",
       "299  POLYGON Z ((-9015596.0256 2844170.7527 0,-9015...    MONROE   \n",
       "300  POLYGON Z ((-9016208.8296 2843020.5594 0,-9016...    MONROE   \n",
       "301  POLYGON Z ((-8927112.0082 2930542.2383 0,-8927...      DADE   \n",
       "\n",
       "                   NAME  created_user  created_date  last_edited_user  \\\n",
       "0            UNSURVEYED           NaN           NaN               NaN   \n",
       "1            HANNA PARK           NaN           NaN               NaN   \n",
       "2        GUANA RIVER SP           NaN           NaN               NaN   \n",
       "3            UNSURVEYED           NaN           NaN               NaN   \n",
       "4    WALTON COUNTY BCHS           NaN           NaN               NaN   \n",
       "..                  ...           ...           ...               ...   \n",
       "297  ENP (HIGHLAND BEAC           NaN           NaN               NaN   \n",
       "298  ENP (HIGHLAND BEAC           NaN           NaN               NaN   \n",
       "299    LITTLE CRAWL KEY           NaN           NaN               NaN   \n",
       "300        FAT DEER KEY           NaN           NaN               NaN   \n",
       "301   BISCAYNE NATIONAL           NaN           NaN               NaN   \n",
       "\n",
       "     last_edited_date  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "..                ...  \n",
       "297               NaN  \n",
       "298               NaN  \n",
       "299               NaN  \n",
       "300               NaN  \n",
       "301               NaN  \n",
       "\n",
       "[302 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('florida-beach-names.csv')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[ds['NAME'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing thats gonna happen is we gonna get rid of the empty columns and the 3 null rows since non of that is gonna give any useful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We make a copy of the data to work on that\n",
    "df = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['created_user', 'created_date', 'last_edited_user', 'last_edited_date', 'WKT'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok we dont have any nan rows in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on our info of the beaches we are gonna find their approximate latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = None\n",
    "df['longitude'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the two empty columns holding the coordenates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    county = row['COUNTY']\n",
    "    name = row['NAME']\n",
    "    coordinates = get_coordinates(county, name)\n",
    "    df.at[index, 'latitude'] = coordinates[0]\n",
    "    df.at[index, 'longitude'] = coordinates[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also noticed some beaches sharing the same name in the same county, so we are gonna drop those and keep just one for each county since it will create the same entries of location with our geolocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['NAME']!='UNSURVEYED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['COUNTY'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can notice how maybe some counties are repeated, SARASOTA and SARASOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[filtered_df['COUNTY'] == 'SARASOTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[filtered_df['COUNTY']=='SARASOAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df[filtered_df['COUNTY']!= 'SARASOAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[filtered_df.duplicated(subset='NAME', keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the coordinates of duplicate beach names on a map shows that the following rows are irrelavant (inland) and can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop([63, 30, 113, 109, 85, 147, 32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be a misspelling so gonna get rid of that line since is already in the other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df['coordinates'] = list(zip(filtered_df['latitude'], filtered_df['longitude']))\n",
    "filtered_df = filtered_df.drop(['latitude', 'longitude'], axis=1)\n",
    "filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df[filtered_df.coordinates.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop_duplicates(subset='coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('updated_beaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the data so it can be used later in the script without going thru all this changes again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = pd.read_csv('updated_beaches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_location = get_coordinates('1200 Anastasia Ave', 'Coral Gables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test location. Soon to be filled with the txt value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_location_list = ['Coral Gables', 'Starting Location', starting_location[0], starting_location[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[len(df.index)] = starting_location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df[(filtered_df.COUNTY == 'BOWARD') | (filtered_df.COUNTY == 'BROWARD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "for index, beach in df.iterrows():\n",
    "    if beach['NAME'] != 'Starting Location':\n",
    "        dist = manhattan_distance(starting_location[0], starting_location[1], beach['latitude'], beach['longitude'])\n",
    "        distances.append(dist)\n",
    "\n",
    "filtered_df['distances'] = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def manhattan_distance(lat1, lon1, lat2, lon2):\n",
    "    return abs(lat2 - lat1) + abs(lon2 - lon1)\n",
    "\n",
    "# Calculate the distance matrix\n",
    "n = len(beaches_df)\n",
    "dist_matrix = np.zeros((n, n))\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            dist_matrix[i, j] = manhattan_distance(beaches_df.loc[i, 'latitude'], beaches_df.loc[i, 'longitude'],\n",
    "                                                   beaches_df.loc[j, 'latitude'], beaches_df.loc[j, 'longitude'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Scraping Data (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import random\n",
    "from itertools import permutations\n",
    "\n",
    "# API key to gain access to Open Cage Geo Data\n",
    "API_KEY = '1232cd7984e543e188eebab0f8d6956f'\n",
    "\n",
    "# Function to get coordinates\n",
    "def get_coordinates(county, name, state=\"Florida\"):\n",
    "    place_name = f\"{name}, {county} County, {state}\"\n",
    "    url = f\"https://api.opencagedata.com/geocode/v1/json?q={place_name}&key={API_KEY}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if data['results']:\n",
    "        location = data['results'][0]['geometry']\n",
    "        return (location['lat'], location['lng'])\n",
    "    else:\n",
    "        return (None, None)\n",
    "\n",
    "# Load dataset\n",
    "ds = pd.read_csv('florida-beach-names.csv')\n",
    "\n",
    "# Make copy of dataframe\n",
    "df = ds.copy()\n",
    "\n",
    "# Preprocessing steps - dropping null values\n",
    "df.drop(columns=['created_user', 'created_date', 'last_edited_user', 'last_edited_date', 'WKT'], inplace = True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Add latitude and longitude data\n",
    "df['latitude'] = None\n",
    "df['longitude'] = None\n",
    "for index, row in df.iterrows():\n",
    "    county = row['COUNTY']\n",
    "    name = row['NAME']\n",
    "    coordinates = get_coordinates(county, name)\n",
    "    df.at[index, 'latitude'] = coordinates[0]\n",
    "    df.at[index, 'longitude'] = coordinates[1]\n",
    "\n",
    "# Zip this data into coordinates\n",
    "filtered_df['coordinates'] = list(zip(filtered_df['latitude'], filtered_df['longitude']))\n",
    "filtered_df = filtered_df.drop(['latitude', 'longitude'], axis=1)\n",
    "\n",
    "# Deal with duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "filtered_df = df[df['NAME']!='UNSURVEYED'] # Missing name\n",
    "filtered_df = filtered_df[filtered_df['COUNTY']!= 'SARASOAT'] # Typo\n",
    "filtered_df = filtered_df.drop([63, 30, 113, 109, 85, 147, 32]) # Duplicate names, not actually beach locations\n",
    "filtered_df = filtered_df.drop_duplicates(subset='coordinates') # Drop duplicate coordinates\n",
    "\n",
    "# Save preprocessed dataset to csv\n",
    "filtered_df.reset_index(drop=True)\n",
    "filtered_df.to_csv('updated_beaches.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing from CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting beach:  hanna park\n",
      "Enter the number of additional beaches:  9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"optimal_route_sequence\": [\n",
      "        \"HANNA PARK\",\n",
      "        \"ST GEO ISL\",\n",
      "        \"ST GEO ISL SP\",\n",
      "        \"DOG ISL\",\n",
      "        \"ST VINCENT NWR\",\n",
      "        \"FT CLINCH SP\",\n",
      "        \"L TALBOT ISL SP\",\n",
      "        \"S COUNTY BCHS\",\n",
      "        \"PONTE VEDRA N\",\n",
      "        \"PONTE VEDRA S\"\n",
      "    ],\n",
      "    \"distances_between_beaches\": [\n",
      "        21.73,\n",
      "        1.6,\n",
      "        0.05,\n",
      "        8.89,\n",
      "        13.88,\n",
      "        11.77,\n",
      "        0.41,\n",
      "        22.35,\n",
      "        15.42\n",
      "    ],\n",
      "    \"total_distance\": 96.1,\n",
      "    \"coordinates\": [\n",
      "        [\n",
      "            30.3709553,\n",
      "            -81.4028428\n",
      "        ],\n",
      "        [\n",
      "            30.685597,\n",
      "            -81.429754\n",
      "        ],\n",
      "        [\n",
      "            30.677999,\n",
      "            -81.455209\n",
      "        ],\n",
      "        [\n",
      "            30.678079,\n",
      "            -81.456019\n",
      "        ],\n",
      "        [\n",
      "            30.573019,\n",
      "            -81.542569\n",
      "        ],\n",
      "        [\n",
      "            30.61058,\n",
      "            -81.77142\n",
      "        ],\n",
      "        [\n",
      "            30.474452,\n",
      "            -81.65222\n",
      "        ],\n",
      "        [\n",
      "            30.4686,\n",
      "            -81.650746\n",
      "        ],\n",
      "        [\n",
      "            30.2396865,\n",
      "            -81.3856384\n",
      "        ],\n",
      "        [\n",
      "            30.0224671,\n",
      "            -81.3236866\n",
      "        ]\n",
      "    ]\n",
      "}\n",
      "               NAME                coordinates  geodesic_distance\n",
      "0        HANNA PARK  (30.3709553, -81.4028428)           0.000000\n",
      "60       ST GEO ISL    (30.685597, -81.429754)          21.733763\n",
      "56    ST GEO ISL SP    (30.677999, -81.455209)          21.380326\n",
      "59          DOG ISL    (30.678079, -81.456019)          21.392885\n",
      "49   ST VINCENT NWR    (30.573019, -81.542569)          16.225112\n",
      "34     FT CLINCH SP      (30.61058, -81.77142)          27.494445\n",
      "29  L TALBOT ISL SP     (30.474452, -81.65222)          16.506379\n",
      "37    S COUNTY BCHS      (30.4686, -81.650746)          16.256565\n",
      "39    PONTE VEDRA N  (30.2396865, -81.3856384)           9.100565\n",
      "41    PONTE VEDRA S  (30.0224671, -81.3236866)          24.467559\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_5316158cf28ad3cf7a765dba7bd6c016 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_5316158cf28ad3cf7a765dba7bd6c016&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_5316158cf28ad3cf7a765dba7bd6c016 = L.map(\n",
       "                &quot;map_5316158cf28ad3cf7a765dba7bd6c016&quot;,\n",
       "                {\n",
       "                    center: [27.9944024, -81.7602544],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 6,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_c2e7b0e5f3a55eb5b34c06ba254c99aa = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_c2e7b0e5f3a55eb5b34c06ba254c99aa.addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "            var marker_3b9bc593bec6ade0d41303c5325837a3 = L.marker(\n",
       "                [30.3709553, -81.4028428],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_db51803a0a9c2cec3397f8eb2f9cfa0b = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_2ef367b40af2495272e5d05a97451919 = $(`&lt;div id=&quot;html_2ef367b40af2495272e5d05a97451919&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;HANNA PARK&lt;br&gt;Coordinates: (30.3709553, -81.4028428)&lt;/div&gt;`)[0];\n",
       "                popup_db51803a0a9c2cec3397f8eb2f9cfa0b.setContent(html_2ef367b40af2495272e5d05a97451919);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_3b9bc593bec6ade0d41303c5325837a3.bindPopup(popup_db51803a0a9c2cec3397f8eb2f9cfa0b)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_11b2e1764c728a09a07d05e491def28c = L.marker(\n",
       "                [30.685597, -81.429754],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_c8e89cb0972b547f45dce24eb84aa272 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_89372e23394d1efda3be07a8d565d993 = $(`&lt;div id=&quot;html_89372e23394d1efda3be07a8d565d993&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;ST GEO ISL&lt;br&gt;Coordinates: (30.685597, -81.429754)&lt;/div&gt;`)[0];\n",
       "                popup_c8e89cb0972b547f45dce24eb84aa272.setContent(html_89372e23394d1efda3be07a8d565d993);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_11b2e1764c728a09a07d05e491def28c.bindPopup(popup_c8e89cb0972b547f45dce24eb84aa272)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_244e819f5f8da3c67e6732aef4ddc3c6 = L.marker(\n",
       "                [30.677999, -81.455209],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_30af24c0d1e0539c03c78f376780d359 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_afdd0768ad66dfb5837f0043750e49cd = $(`&lt;div id=&quot;html_afdd0768ad66dfb5837f0043750e49cd&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;ST GEO ISL SP&lt;br&gt;Coordinates: (30.677999, -81.455209)&lt;/div&gt;`)[0];\n",
       "                popup_30af24c0d1e0539c03c78f376780d359.setContent(html_afdd0768ad66dfb5837f0043750e49cd);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_244e819f5f8da3c67e6732aef4ddc3c6.bindPopup(popup_30af24c0d1e0539c03c78f376780d359)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_c3335ad6311cc74dbe2875fb46854041 = L.marker(\n",
       "                [30.678079, -81.456019],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_de1a5c389af09fb4974dafc7cd8fb7e7 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_b5d92d0dc441c747fe6b3cef300b74bc = $(`&lt;div id=&quot;html_b5d92d0dc441c747fe6b3cef300b74bc&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;DOG ISL&lt;br&gt;Coordinates: (30.678079, -81.456019)&lt;/div&gt;`)[0];\n",
       "                popup_de1a5c389af09fb4974dafc7cd8fb7e7.setContent(html_b5d92d0dc441c747fe6b3cef300b74bc);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_c3335ad6311cc74dbe2875fb46854041.bindPopup(popup_de1a5c389af09fb4974dafc7cd8fb7e7)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_c4df13ef05177bf627116f53c6b89b6b = L.marker(\n",
       "                [30.573019, -81.542569],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_e553dcf6586da63974e9088267a98b5c = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_0068b6ac4af650d86c8c541eadd288bd = $(`&lt;div id=&quot;html_0068b6ac4af650d86c8c541eadd288bd&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;ST VINCENT NWR&lt;br&gt;Coordinates: (30.573019, -81.542569)&lt;/div&gt;`)[0];\n",
       "                popup_e553dcf6586da63974e9088267a98b5c.setContent(html_0068b6ac4af650d86c8c541eadd288bd);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_c4df13ef05177bf627116f53c6b89b6b.bindPopup(popup_e553dcf6586da63974e9088267a98b5c)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_4cf5c11ab3b748bf6b65e9603e573477 = L.marker(\n",
       "                [30.61058, -81.77142],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_e18e4d6033a4ba3d192ed74490735a6a = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_d69eefb4c89b5e032e80d15cc0a27705 = $(`&lt;div id=&quot;html_d69eefb4c89b5e032e80d15cc0a27705&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;FT CLINCH SP&lt;br&gt;Coordinates: (30.61058, -81.77142)&lt;/div&gt;`)[0];\n",
       "                popup_e18e4d6033a4ba3d192ed74490735a6a.setContent(html_d69eefb4c89b5e032e80d15cc0a27705);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_4cf5c11ab3b748bf6b65e9603e573477.bindPopup(popup_e18e4d6033a4ba3d192ed74490735a6a)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_d67312a5fbc84fabaa36ca08615b819c = L.marker(\n",
       "                [30.474452, -81.65222],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_d921af1d33e1bfd68dbdef09293af37c = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_c569bbc90348b32f967a8482d504b608 = $(`&lt;div id=&quot;html_c569bbc90348b32f967a8482d504b608&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;L TALBOT ISL SP&lt;br&gt;Coordinates: (30.474452, -81.65222)&lt;/div&gt;`)[0];\n",
       "                popup_d921af1d33e1bfd68dbdef09293af37c.setContent(html_c569bbc90348b32f967a8482d504b608);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_d67312a5fbc84fabaa36ca08615b819c.bindPopup(popup_d921af1d33e1bfd68dbdef09293af37c)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_e85a6ea811ea093b99ff91d1e4f12bb6 = L.marker(\n",
       "                [30.4686, -81.650746],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_37b2894e859cbd76227b3c11f030ccd2 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_04d8801d32bb1ee5895e3b617bcd1315 = $(`&lt;div id=&quot;html_04d8801d32bb1ee5895e3b617bcd1315&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;S COUNTY BCHS&lt;br&gt;Coordinates: (30.4686, -81.650746)&lt;/div&gt;`)[0];\n",
       "                popup_37b2894e859cbd76227b3c11f030ccd2.setContent(html_04d8801d32bb1ee5895e3b617bcd1315);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_e85a6ea811ea093b99ff91d1e4f12bb6.bindPopup(popup_37b2894e859cbd76227b3c11f030ccd2)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_05699a4bf3b2aebcf360f0f636728d34 = L.marker(\n",
       "                [30.2396865, -81.3856384],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_f18b00a8e8515b5be396bcaa3ce8ed6d = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_07462ede0558cd60f1091ec2d2e61169 = $(`&lt;div id=&quot;html_07462ede0558cd60f1091ec2d2e61169&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;PONTE VEDRA N&lt;br&gt;Coordinates: (30.2396865, -81.3856384)&lt;/div&gt;`)[0];\n",
       "                popup_f18b00a8e8515b5be396bcaa3ce8ed6d.setContent(html_07462ede0558cd60f1091ec2d2e61169);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_05699a4bf3b2aebcf360f0f636728d34.bindPopup(popup_f18b00a8e8515b5be396bcaa3ce8ed6d)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var marker_14b4a3357d20743b04a7886a2f599f29 = L.marker(\n",
       "                [30.0224671, -81.3236866],\n",
       "                {}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "        var popup_a1b03ee4cd2191365681c7a1ca0e6594 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_3ad8c90fa27c3f7b9f983f2d4289b250 = $(`&lt;div id=&quot;html_3ad8c90fa27c3f7b9f983f2d4289b250&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;PONTE VEDRA S&lt;br&gt;Coordinates: (30.0224671, -81.3236866)&lt;/div&gt;`)[0];\n",
       "                popup_a1b03ee4cd2191365681c7a1ca0e6594.setContent(html_3ad8c90fa27c3f7b9f983f2d4289b250);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_14b4a3357d20743b04a7886a2f599f29.bindPopup(popup_a1b03ee4cd2191365681c7a1ca0e6594)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            var poly_line_b5865f9f71f8f563cadd06cbdf2a88cd = L.polyline(\n",
       "                [[30.3709553, -81.4028428], [30.685597, -81.429754], [30.677999, -81.455209], [30.678079, -81.456019], [30.573019, -81.542569], [30.61058, -81.77142], [30.474452, -81.65222], [30.4686, -81.650746], [30.2396865, -81.3856384], [30.0224671, -81.3236866]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;blue&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;blue&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 1, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 2.5}\n",
       "            ).addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "    \n",
       "            tile_layer_c2e7b0e5f3a55eb5b34c06ba254c99aa.addTo(map_5316158cf28ad3cf7a765dba7bd6c016);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x1db891cb9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "import random\n",
    "from itertools import permutations\n",
    "import json\n",
    "import folium\n",
    "\n",
    "def preprocess(file_path):\n",
    "    \"\"\"\n",
    "    Preprocesses csv dataset.\n",
    "    \"\"\"\n",
    "    filtered_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Zip this data into coordinates\n",
    "    filtered_df['coordinates'] = list(zip(filtered_df['latitude'], filtered_df['longitude']))\n",
    "    filtered_df = filtered_df.drop(['latitude', 'longitude'], axis=1)\n",
    "    \n",
    "    # Deal with duplicates\n",
    "    filtered_df = filtered_df.drop([63, 30, 113, 109, 85, 147, 32]) # Duplicate names, not actually beach locations\n",
    "    filtered_df.drop_duplicates(inplace=True)\n",
    "    filtered_df = filtered_df[filtered_df['NAME'] != 'UNSURVEYED'] # Missing name\n",
    "    filtered_df = filtered_df[filtered_df['COUNTY'] != 'SARASOAT'] # Typo\n",
    "    filtered_df = filtered_df.drop_duplicates(subset='coordinates') # Drop duplicate coordinates\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Function to calculate the nearest n beaches from the starting beach\n",
    "def calculate_nearest_beaches(df, starting_beach, n):\n",
    "    \"\"\"\n",
    "    Calculate nearest n beaches from starting beach, using geodesic distance between lat/long coordinates.\n",
    "    \n",
    "    Inputs: \n",
    "        - df: DataFrame of all beach data, \n",
    "        - starting_beach: string, precise name of starting beach according to provided df\n",
    "        - n: int, number of nearest beaches to calculate\n",
    "\n",
    "    Output:\n",
    "        - DataFrame containing name of beach and geodesic distance (in miles) from starting beach\n",
    "    \"\"\"\n",
    "    starting_beach_coord = df[df.NAME.str.upper() == starting_beach.upper()].coordinates.iloc[0]\n",
    "    df = df.copy()\n",
    "    df['geodesic_distance'] = df['coordinates'].apply(lambda x: geodesic(starting_beach_coord, x).miles)\n",
    "    df = df.sort_values(by='geodesic_distance', ascending=True).head(n + 1)\n",
    "    return df[['NAME', 'coordinates', 'geodesic_distance']]\n",
    "\n",
    "# Function to calculate the distance matrix\n",
    "def calculate_distance_matrix(df):\n",
    "    \"\"\"\n",
    "    Calculate distance matrix between every point in a dataframe.\n",
    "\n",
    "    Input:\n",
    "        - Dataframe, including coordinates\n",
    "    Output:\n",
    "        - Distance matrix (list of lists, including distance from each point to every other point)\n",
    "    \"\"\"\n",
    "    coords = df['coordinates'].tolist()\n",
    "    distance_matrix = squareform(pdist(coords, lambda u, v: geodesic(u, v).miles))\n",
    "    return distance_matrix\n",
    "\n",
    "# Nearest Neighbor Algorithm to find the optimal route and calculate total distance\n",
    "def nearest_neighbor_algorithm(distance_matrix):\n",
    "    \"\"\"\n",
    "    Uses Nearest Neighbor algorithm to find a good route.\n",
    "\n",
    "    Input: \n",
    "        - Distance matrix (list of lists, including distance from each point to every other point)\n",
    "    Output:\n",
    "        - Route (list of location names)\n",
    "        - Total distance (miles)\n",
    "        - Distances (list of distances between each location, miles)\n",
    "    \"\"\"\n",
    "    n = len(distance_matrix)\n",
    "    visited = [False] * n\n",
    "    route = [0]  # Start from the initial location\n",
    "    visited[0] = True\n",
    "    total_distance = 0.0\n",
    "    distances = []\n",
    "\n",
    "    for _ in range(1, n):\n",
    "        last_visited = route[-1]\n",
    "        next_city = np.argmin([distance_matrix[last_visited][j] if not visited[j] else float('inf') for j in range(n)])\n",
    "        route.append(next_city)\n",
    "        visited[next_city] = True\n",
    "        distance = round(distance_matrix[last_visited][next_city], 2)\n",
    "        distances.append(distance)\n",
    "        total_distance += distance\n",
    "\n",
    "    return route, total_distance, distances\n",
    "\n",
    "def calculate_random_route(distance_matrix):\n",
    "    \"\"\"\n",
    "    Uses randomization to calculate a baseline route.\n",
    "\n",
    "    Input: \n",
    "        - Distance matrix (list of lists, including distance from each point to every other point)\n",
    "    Output:\n",
    "        - Route (list of location names)\n",
    "        - Total distance (miles)\n",
    "        - Distances (list of distances between each location, miles)    \n",
    "    \"\"\"\n",
    "    n = len(distance_matrix)\n",
    "    route = list(range(1, n))  # Start from the second location\n",
    "    random.shuffle(route)\n",
    "    route = [0] + route  # Add the starting location at the beginning\n",
    "    total_distance = 0.0\n",
    "    distances = []\n",
    "\n",
    "    for i in range(n - 1):\n",
    "        distance = distance_matrix[route[i]][route[i + 1]]\n",
    "        distances.append(f\"{distance:.2f}\")\n",
    "        total_distance += distance\n",
    "\n",
    "    return route, total_distance, distances\n",
    "\n",
    "# Brute Force Algorithm to find the optimal route and calculate total distance\n",
    "def calculate_brute_force_route(distance_matrix):\n",
    "    \"\"\"\n",
    "    Uses a brute force approach to find the best route.\n",
    "\n",
    "    Input: \n",
    "        - Distance matrix (list of lists, including distance from each point to every other point)\n",
    "    Output:\n",
    "        - Route (list of location names)\n",
    "        - Total distance (miles)\n",
    "        - Distances (list of distances between each location, miles)   \n",
    "    \"\"\"\n",
    "    n = len(distance_matrix)\n",
    "    min_distance = float('inf')\n",
    "    best_route = None\n",
    "    best_distances = []\n",
    "\n",
    "    for perm in permutations(range(1, n)):\n",
    "        current_route = [0] + list(perm)\n",
    "        current_distance = 0.0\n",
    "        distances = []\n",
    "\n",
    "        for i in range(n - 1):\n",
    "            distance = distance_matrix[current_route[i]][current_route[i + 1]]\n",
    "            distances.append(f\"{distance:.2f}\")\n",
    "            current_distance += distance\n",
    "\n",
    "        if current_distance < min_distance:\n",
    "            min_distance = current_distance\n",
    "            best_route = current_route\n",
    "            best_distances = distances\n",
    "\n",
    "    return best_route, min_distance, best_distances\n",
    "\n",
    "# Main function to call the other functions and get the optimal route and total distance\n",
    "def calculate_route(df, starting_beach, n, algorithm='nearest neighbors'):\n",
    "    \"\"\"\n",
    "    Calculate optimal route from start to finish, calling other functions. Choose between performance/efficiency levels.\n",
    "\n",
    "    Inputs: \n",
    "        - df: DataFrame of all location data\n",
    "        - starting_beach: string, precise name of starting location/beach according to provided df\n",
    "        - n: int, number of nearest locations to calculate. Refer to algorithm parameter for guidance on maximum size of n.\n",
    "        - algorithm: string, one of three options:\n",
    "            - 'nearest neighbors': best value of performance and efficiency (n has no upper limit)\n",
    "            - 'random': most efficient, but poor performance (baseline model, n has no upper limit)\n",
    "            - 'brute force': highest performance, lowest efficiency (n cannot exceed 9 without massive performance loss)\n",
    "    Outputs:\n",
    "        - optimal route: ordered list of locations, beginning with starting location\n",
    "        - total distance: float, total distance traveled from starting location to final location, miles\n",
    "        - distances: ordered list of distances between each location, miles\n",
    "    \"\"\"\n",
    "    nearest_beaches = calculate_nearest_beaches(df, starting_beach, n)\n",
    "    distance_matrix = calculate_distance_matrix(nearest_beaches)\n",
    "    \n",
    "    if algorithm.lower() == 'nearest neighbors':\n",
    "        route_indices, total_distance, distances = nearest_neighbor_algorithm(distance_matrix)\n",
    "    elif algorithm.lower() == 'random':\n",
    "        route_indices, total_distance, distances = calculate_random_route(distance_matrix)\n",
    "    elif algorithm.lower() == 'brute force':\n",
    "        route_indices, total_distance, distances = calculate_brute_force_route(distance_matrix)\n",
    "    \n",
    "    optimal_route = nearest_beaches.iloc[route_indices]\n",
    "    \n",
    "    route = optimal_route.NAME.tolist()\n",
    "    coordinates = optimal_route.coordinates.tolist()\n",
    "    distances = [float(d) for d in distances]  # Convert distances to float\n",
    "    \n",
    "    result = {\n",
    "        'optimal_route_sequence': route,\n",
    "        'distances_between_beaches': distances,\n",
    "        'total_distance': round(total_distance, 2),\n",
    "        'coordinates': coordinates\n",
    "    }\n",
    "    \n",
    "    return json.dumps(result, indent=4), optimal_route\n",
    "\n",
    "def plot_route(optimal_route):\n",
    "    \"\"\"\n",
    "    Plots the optimal route on an interactive map.\n",
    "    \n",
    "    Inputs:\n",
    "        - optimal_route: DataFrame containing the optimal route with names and coordinates\n",
    "    \"\"\"\n",
    "    # Initialize the map centered around Florida\n",
    "    m = folium.Map(location=[27.9944024, -81.7602544], zoom_start=6)\n",
    "    \n",
    "    # Add markers and lines for the optimal route\n",
    "    points = []\n",
    "    for idx, row in optimal_route.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[row['coordinates'][0], row['coordinates'][1]],\n",
    "            popup=f\"{row['NAME']}<br>Coordinates: {row['coordinates']}\"\n",
    "        ).add_to(m)\n",
    "        points.append((row['coordinates'][0], row['coordinates'][1]))\n",
    "    \n",
    "    folium.PolyLine(points, color=\"blue\", weight=2.5, opacity=1).add_to(m)\n",
    "    \n",
    "    return m\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the filtered DataFrame\n",
    "    filtered_df = preprocess('updated_beaches.csv')\n",
    "    \n",
    "    # User input for starting beach and number of additional beaches\n",
    "    starting_beach = input(\"Enter the starting beach: \")\n",
    "    n = int(input(\"Enter the number of additional beaches: \"))\n",
    "    \n",
    "    # Calculate the route using the desired algorithm\n",
    "    result_json, optimal_route = calculate_route(filtered_df, starting_beach, n, algorithm='brute force')\n",
    "\n",
    "    # Print the JSON result\n",
    "    print(result_json)\n",
    "    print(optimal_route)\n",
    "\n",
    "    # Plot and save the route map\n",
    "    route_map = plot_route(optimal_route)\n",
    "    route_map.save('route_map.html')\n",
    "\n",
    "    # Display the route map (if using a Jupyter Notebook)\n",
    "    display(route_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Google Maps Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'AIzaSyAGcEda7gNv_YZM95Z2a_6ioomdbUwOntI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'updated_beaches.csv'\n",
    "beaches_df = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the starting beach\n",
    "starting_beach = beaches_df.iloc[0]\n",
    "\n",
    "# Extract coordinates for origins and destinations\n",
    "origins = [f\"{starting_beach['latitude']},{starting_beach['longitude']}\"]\n",
    "destinations = [f\"{row['latitude']},{row['longitude']}\" for _, row in beaches_df.iterrows() if row['NAME'] != starting_beach['NAME']]\n",
    "\n",
    "def get_distance_matrix(api_key, origins, destinations):\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "    all_elements = []\n",
    "    \n",
    "    # Batch the destinations to avoid exceeding the limit\n",
    "    batch_size = 100 // len(origins)\n",
    "    for i in range(0, len(destinations), batch_size):\n",
    "        batch_destinations = destinations[i:i + batch_size]\n",
    "        params = {\n",
    "            \"origins\": \"|\".join(origins),\n",
    "            \"destinations\": \"|\".join(batch_destinations),\n",
    "            \"key\": api_key,\n",
    "            \"departure_time\": \"now\",\n",
    "            \"traffic_model\": \"best_guess\"\n",
    "        }\n",
    "        response = requests.get(base_url, params=params)\n",
    "        result = response.json()\n",
    "        \n",
    "        if result['status'] == 'OK':\n",
    "            all_elements.extend(result['rows'][0]['elements'])\n",
    "        else:\n",
    "            print(\"Error in API response:\", result['status'])\n",
    "            return None\n",
    "    \n",
    "    return all_elements\n",
    "\n",
    "# Your Google Maps API key\n",
    "api_key = 'YOUR_GOOGLE_MAPS_API_KEY'\n",
    "\n",
    "# Get distance matrix\n",
    "distance_elements = get_distance_matrix(api_key, origins, destinations)\n",
    "\n",
    "# Check if the distance_elements is None\n",
    "if distance_elements is None:\n",
    "    print(\"Error occurred while fetching distance matrix.\")\n",
    "else:\n",
    "    # Process the distance matrix to find the closest beaches\n",
    "    distances = [element['duration']['value'] for element in distance_elements]\n",
    "    beaches_df = beaches_df[beaches_df['NAME'] != starting_beach['NAME']]\n",
    "    beaches_df['travel_time'] = distances\n",
    "\n",
    "    # Find the ten closest beaches based on travel time\n",
    "    closest_beaches = beaches_df.nsmallest(10, 'travel_time')\n",
    "\n",
    "    # Display the closest beaches\n",
    "    print(closest_beaches)\n",
    "\n",
    "    # Create data model for TSP\n",
    "    def create_data_model(closest_beaches):\n",
    "        \"\"\"Stores the data for the problem.\"\"\"\n",
    "        data = {}\n",
    "        travel_times = closest_beaches['travel_time'].tolist()\n",
    "        num_beaches = len(travel_times) + 1\n",
    "        distance_matrix = [[0] * num_beaches for _ in range(num_beaches)]\n",
    "        for i in range(1, num_beaches):\n",
    "            distance_matrix[0][i] = travel_times[i-1]\n",
    "            distance_matrix[i][0] = travel_times[i-1]\n",
    "        data['distance_matrix'] = distance_matrix\n",
    "        data['num_vehicles'] = 1\n",
    "        data['depot'] = 0\n",
    "        return data\n",
    "\n",
    "    # Solve the TSP\n",
    "    def main():\n",
    "        closest_beaches = closest_beaches.reset_index()\n",
    "        data = create_data_model(closest_beaches)\n",
    "\n",
    "        # Create the routing index manager.\n",
    "        manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\n",
    "                                               data['num_vehicles'], data['depot'])\n",
    "\n",
    "        # Create Routing Model.\n",
    "        routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "        def distance_callback(from_index, to_index):\n",
    "            \"\"\"Returns the travel time between the two nodes.\"\"\"\n",
    "            from_node = manager.IndexToNode(from_index)\n",
    "            to_node = manager.IndexToNode(to_index)\n",
    "            return data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "        transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "\n",
    "        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "        search_parameters.first_solution_strategy = (\n",
    "            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "\n",
    "        solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "        if solution:\n",
    "            print_solution(manager, routing, solution)\n",
    "\n",
    "    def print_solution(manager, routing, solution):\n",
    "        \"\"\"Prints solution on console.\"\"\"\n",
    "        print('Objective: {}'.format(solution.ObjectiveValue()))\n",
    "        index = routing.Start(0)\n",
    "        plan_output = 'Route:\\n'\n",
    "        route_distance = 0\n",
    "        while not routing.IsEnd(index):\n",
    "            plan_output += ' {} ->'.format(manager.IndexToNode(index))\n",
    "            previous_index = index\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "            route_distance += routing.GetArcCostForVehicle(previous_index, index, 0)\n",
    "        plan_output += ' {}\\n'.format(manager.IndexToNode(index))\n",
    "        print(plan_output)\n",
    "        print('Route distance: {}'.format(route_distance))\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def verify_api_key(api_key):\n",
    "    test_url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "    params = {\n",
    "        \"origins\": \"30.370955,-81.402843\",\n",
    "        \"destinations\": \"29.912180,-81.409890\",\n",
    "        \"key\": api_key,\n",
    "    }\n",
    "    response = requests.get(test_url, params=params)\n",
    "    return response.json()\n",
    "\n",
    "# Your Google Maps API key\n",
    "api_key = 'YOUR_GOOGLE_MAPS_API_KEY'\n",
    "\n",
    "# Verify the API key\n",
    "response = verify_api_key(api_key)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
